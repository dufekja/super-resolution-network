{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b6795e-af36-4327-a597-4a139e66e9c8",
   "metadata": {},
   "source": [
    "Datasets: [here](https://paperswithcode.com/datasets?q=&v=lst&o=match&mod=images&task=image-super-resolution)\n",
    "\n",
    "## Sources\n",
    "- https://paperswithcode.com/dataset/div2k\n",
    "- https://github.com/sgrvinod/Deep-Tutorials-for-PyTorch\n",
    "- https://jonathan-hui.medium.com/gan-super-resolution-gan-srgan-b471da7270ec\n",
    "\n",
    "## Concepts\n",
    "- GAN - one NN for superres and second one for img rating in zero-sum game\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e4c39-41e5-4ed8-acfc-629c5030cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from torch import nn\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(SEED) \n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7f76d-c006-41e4-b5c8-bc2382630725",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgTransform(object):\n",
    "    def __init__(self, crop, scale, is_train=True, output='Tensor'):\n",
    "        self.crop = crop\n",
    "        self.scale = scale\n",
    "        self.is_train = is_train\n",
    "        self.output = output\n",
    "\n",
    "    def __call__(self, img):\n",
    "\n",
    "        if self.is_train:\n",
    "            \n",
    "            # crop HR image \n",
    "            left, top = random.randint(0, img.width - self.crop), random.randint(0, img.height - self.crop)\n",
    "            right, bottom = left + self.crop, top + self.crop\n",
    "    \n",
    "            hr_img = img.crop((left, top, right, bottom))\n",
    "        else:\n",
    "            right, bottom = (img.width // self.scale) * self.scale, (img.height // self.scale) * self.scale\n",
    "            hr_img = img.crop((0, 0, right, bottom))     \n",
    "            \n",
    "        # downscale hr image\n",
    "        lr_img = hr_img.resize((hr_img.width // self.scale, hr_img.height // self.scale), Image.BICUBIC)\n",
    "        \n",
    "        assert lr_img.width * self.scale == hr_img.width\n",
    "        assert lr_img.height * self.scale == hr_img.height\n",
    "        assert (hr_img.width % self.scale, hr_img.height % self.scale) == (0, 0)\n",
    "        \n",
    "        # convert to tensor\n",
    "        if self.output == 'Tensor':\n",
    "            return pil_to_tensor(lr_img), pil_to_tensor(hr_img)\n",
    "        \n",
    "        return lr_img, hr_img\n",
    "\n",
    "class Div2kDataset(Dataset):\n",
    "    def __init__(self, dir='./data', transform=None):\n",
    "        self.dir = dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.images = sorted([x for x in os.listdir(self.dir)])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(f'{self.dir}/{self.images[idx]}')\n",
    "\n",
    "        if self.transform:\n",
    "            return self.transform(img)\n",
    "            \n",
    "train_dataset = Div2kDataset('DIV2K/HR', transform=ImgTransform(crop=128, scale=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e286d9b-f806-445f-96ac-9f1941f50267",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcda663-e97a-4b62-9fca-9d040ae84856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bf01b-45bb-49dd-ab2b-3c8ced3514c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()\n",
    "\n",
    "loader = iter(train_dataloader)\n",
    "lr, hr = next(loader)\n",
    "\n",
    "gen.forward(lr.type(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b51c8a4-e828-446a-882e-640483445498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
