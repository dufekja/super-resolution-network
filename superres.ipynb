{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Resolution Network\n",
    "\n",
    "This notebook is made as a basic guideline to training and using superres model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import metrics\n",
    "from models import Generator, SResNet, Discriminator\n",
    "\n",
    "# custom modules\n",
    "from utils import convert_img, upscale_img\n",
    "\n",
    "# select model scale\n",
    "SCALE = 2 \n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(SEED) \n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain dataset\n",
    "Run next cell to download `DIV2K` dataset or use any high-resolution image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebe3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model based on configuration\n",
    "\n",
    "Configure `train_sresnet.py` and run next cell to initiate training or skip this step if you already have trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_sresnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model\n",
    "\n",
    "Load trained model with name in `PT_SAVED`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_SAVED = '2x-sresnet.pt' \n",
    "\n",
    "model = torch.load(PT_SAVED)['model'].to(DEVICE)\n",
    "model.train(False)\n",
    "\n",
    "print('Model loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upscale image\n",
    "\n",
    "Either choose high-resolution image from image data and downscale it or load low-resolution image without downscaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = 'DIV2K/0420.png'\n",
    "\n",
    "# get high-resolution image\n",
    "hr = Image.open(IMAGE).convert('RGB').crop((200, 400, 800, 1000))\n",
    "\n",
    "# resize high-resolution image using BICUBIC\n",
    "lr = hr.resize((hr.width // SCALE, hr.height // SCALE), Image.BICUBIC)\n",
    "\n",
    "hr, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale low-resolution image in PIL format using given trained model\n",
    "sr = upscale_img(lr, model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot high, low and super resolution images\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "for i, [img, type] in enumerate([(hr, 'high res'), (lr, 'low res'), (sr, 'super res')]):\n",
    "    fig.add_subplot(1, 3, i + 1)\n",
    "    plt.title(type)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "We can use `structural similarity index` or `peak signal noise ratio` to evaluate upscaled images with original high-resolution image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26648fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img, bicubic_img, superres_img = (\n",
    "    np.array(convert_img(hr, 'pil', '[0, 1]')),\n",
    "    np.array(convert_img(lr.resize(hr.size, Image.BICUBIC), 'pil', '[0, 1]')),\n",
    "    np.array(convert_img(sr, 'pil', '[0, 1]'))\n",
    ")\n",
    "\n",
    "# value from range (-1, 1)\n",
    "print(f'SSIM bicubic:  {metrics.structural_similarity(original_img, bicubic_img, channel_axis=0, data_range=1):.3f}') \n",
    "print(f'SSIM superres: {metrics.structural_similarity(original_img, bicubic_img, channel_axis=0, data_range=1):.3f}') \n",
    "\n",
    "print()\n",
    "\n",
    "# higher value means higher similarity (identical img produces zero division)\n",
    "print(f'PSNR bicubic:  {metrics.peak_signal_noise_ratio(original_img, bicubic_img):.3f}') \n",
    "print(f'PSNR superres: {metrics.peak_signal_noise_ratio(original_img, superres_img):.3f}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
