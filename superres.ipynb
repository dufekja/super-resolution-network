{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b6795e-af36-4327-a597-4a139e66e9c8",
   "metadata": {},
   "source": [
    "\n",
    "## Sources\n",
    "- https://paperswithcode.com/dataset/div2k\n",
    "- https://github.com/sgrvinod/Deep-Tutorials-for-PyTorch\n",
    "- https://jonathan-hui.medium.com/gan-super-resolution-gan-srgan-b471da7270ec\n",
    "- https://github.com/labmlai/annotated_deep_learning_paper_implementations\n",
    "- https://gitlab.fit.cvut.cz/dufekja4/bi-ml2-2023-dufekja4/-/blob/hw02/02/homework_02_B222.ipynb?ref_type=heads\n",
    "\n",
    "- SRESNN paper: https://arxiv.org/pdf/1501.00092.pdf\n",
    "- structural similarity: https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf\n",
    "- loss functions for SR: https://arxiv.org/pdf/1511.08861.pdf\n",
    "\n",
    "\n",
    "Dataset used for training: https://data.vision.ee.ethz.ch/cvl/DIV2K/\n",
    "\n",
    "Specifically `High Resolution Images`: train data and validation data\n",
    "\n",
    "\n",
    "## Concepts\n",
    "- GAN - one NN for superres and second one for img rating in zero-sum game\n",
    "- deep learning residual connections\n",
    "- sub pixel convolution\n",
    "- pretrain SRmodel and then use GAN with pretrained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebe3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download DIV2K dataset \n",
    "!python download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e4c39-41e5-4ed8-acfc-629c5030cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "from dataset import Div2kDataset\n",
    "from utils import ImgTransform\n",
    "from models import SResNet\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "SCALE = 2\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(SEED) \n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7f76d-c006-41e4-b5c8-bc2382630725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train image transformer to crop \n",
    "transform = ImgTransform(crop=64, scale=SCALE, is_train=True, output='Tensor')\n",
    "\n",
    "train_dataset = Div2kDataset('DIV2K', transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90641e63-eebf-4ee7-affc-0ccbb1a850e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = SResNet(3, 3, res_block_cnt=10, scale=SCALE).to(DEVICE)\n",
    "criterion = nn.MSELoss().to(DEVICE)\n",
    "\n",
    "optimizer = Adam(gen.parameters())\n",
    "\n",
    "lr, hr = next(iter(train_dataloader))\n",
    "sr = gen(lr)\n",
    "\n",
    "\n",
    "display(len(gen.res_blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b0c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lr.shape, hr.shape, sr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58276c30-3cb9-489b-8b45-e35aa11a262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loader, model, criterion, optimizer):\n",
    "\n",
    "    train_loss = .0\n",
    "    \n",
    "    for [lr, hr] in tqdm(loader, total=len(loader)):\n",
    "        lr, hr = lr.to(DEVICE), hr.to(DEVICE)\n",
    "        \n",
    "        # zero grad and forward batch trough model\n",
    "        optimizer.zero_grad()\n",
    "        sr = model(lr)\n",
    "        \n",
    "        # calculate and backprop loss \n",
    "        loss = criterion(sr, hr)\n",
    "        loss.backward()\n",
    "\n",
    "        # adjust optimizer weights\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * lr.shape[0]\n",
    "        \n",
    "        del lr, hr, sr\n",
    "\n",
    "    print(f\"loss: {train_loss / len(loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f55644-c374-4335-8766-9e30cf79f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch(train_dataloader, gen, criterion, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
