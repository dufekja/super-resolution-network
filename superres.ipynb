{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Resolution Network\n",
    "\n",
    "This notebook serves as a fundamental guide for training and utilizing the superres model.\n",
    " \n",
    "It also includes visual demonstrations and metrics of upscaled images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This cell just imports necessary libraries and sets global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import metrics\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# custom modules\n",
    "from utils import  convert_img, upscale_img, evaluate\n",
    "\n",
    "# select model scale\n",
    "SCALE = 2 \n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED) \n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain dataset\n",
    "Run next cell to download `DIV2K` dataset or use any high-resolution image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebe3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model based on configuration\n",
    "\n",
    "Configure `train_sresnet.py` and run next cell to initiate training or skip this step if you already have a trained model checkpoint (example is `2x-sresnet.pt`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_sresnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model\n",
    "\n",
    "Load trained model with name in `PT_SAVED`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_SAVED = '2x-sresnet.pt'\n",
    "\n",
    "model = torch.load(PT_SAVED)['model'].to(DEVICE)\n",
    "model.train(False)\n",
    "\n",
    "print('Model loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upscale image\n",
    "\n",
    "Either choose high-resolution image from image data and downscale it or load low-resolution image without downscaling.\n",
    "\n",
    "In next cell, the image is manually selected, cropped and downscaled using `Image.BICUBIC` algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = 'DIV2K/0420.png'\n",
    "\n",
    "# get high-resolution image\n",
    "hr = Image.open(IMAGE).convert('RGB').crop((200, 400, 800, 1000))\n",
    "\n",
    "# resize high-resolution image using BICUBIC\n",
    "lr = hr.resize((hr.width // SCALE, hr.height // SCALE), Image.BICUBIC)\n",
    "\n",
    "hr.size, lr.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upscaling can be done manually using model or just calling `upscale_img` with proper params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale low-resolution image in PIL format using given trained model\n",
    "sr = upscale_img(lr, model, input_format='pil', output_format='pil')\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot high, low and super resolution images\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "for i, [img, type] in enumerate([(hr, 'high res'), (lr, 'low res'), (sr, 'super res')]):\n",
    "    fig.add_subplot(1, 3, i + 1)\n",
    "    plt.title(type)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `structural similarity index` or `peak signal noise ratio` to evaluate upscaled images with original high-resolution image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert onto [0, 1] np arrays\n",
    "original_img, bicubic_img, superres_img = (\n",
    "    np.array(convert_img(hr, 'pil', '[0, 1]')),\n",
    "    np.array(convert_img(lr.resize(hr.size, Image.BICUBIC), 'pil', '[0, 1]')),\n",
    "    np.array(convert_img(sr, 'pil', '[0, 1]'))\n",
    ")\n",
    "\n",
    "# value from range (-1, 1)\n",
    "print(f'SSIM bicubic:  {metrics.structural_similarity(original_img, bicubic_img, channel_axis=0, data_range=1):.3f}') \n",
    "print(f'SSIM superres: {metrics.structural_similarity(original_img, bicubic_img, channel_axis=0, data_range=1):.3f}') \n",
    "\n",
    "print()\n",
    "\n",
    "# higher value means higher similarity (identical img produces zero division)\n",
    "print(f'PSNR bicubic:  {metrics.peak_signal_noise_ratio(original_img, bicubic_img):.3f}') \n",
    "print(f'PSNR superres: {metrics.peak_signal_noise_ratio(original_img, superres_img):.3f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SSIM` gives us coef. from range (-1, 1) which represents structural similarity of given images.\n",
    "\n",
    "`PSNR` gives us number which represents quality of reconstructed image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and loss\n",
    "In this section are metrics and loss plots for 2x and 4x sresnets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2x sresnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVALID = 1000\n",
    "\n",
    "# load model state and count epochs without validation\n",
    "model_state = torch.load('2x-sresnet.pt')\n",
    "valid_div = model_state['vloss'].count(INVALID)\n",
    "\n",
    "# get tloss and vloss with y indexes\n",
    "tloss, vloss = model_state['tloss'], model_state['vloss'][valid_div:]\n",
    "y = np.arange(len(tloss))\n",
    "\n",
    "# figure plot\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.subplots()\n",
    "\n",
    "# plot losses\n",
    "ax.plot(y, tloss, 'b-', label='train loss')\n",
    "ax.plot(y[len(tloss) - len(vloss):], vloss, 'r-', label='valid loss')\n",
    "ax.axvline(valid_div, c='green', linestyle=':', label='epoch validation start')\n",
    "\n",
    "ax.set_title('2x sresnet')\n",
    "ax.set_xticks(np.arange(0, len(tloss) + 1, 5))\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Best train loss: {min(tloss):.4f}')\n",
    "print(f'Best valid loss: {min(vloss):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was validated from 25 epoch. We can also see model improvement on both losses.\n",
    "\n",
    "Next, we will run model on random N image crops and then outputs avg `ssim` and `psnr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "N = 100\n",
    "CROP = 512\n",
    "SCALE = 2\n",
    "\n",
    "ssim, psnr = evaluate(N, model_state['model'], SCALE, CROP)\n",
    "\n",
    "print(f'avg SSIM bicubic: {sum(ssim[\"bic\"]) / N:.4f}') \n",
    "print(f'avg SSIM superres:  {sum(ssim[\"sres\"]) / N:.4f}') \n",
    "\n",
    "print()\n",
    "\n",
    "print(f'avg PSNR bicubic:  {sum(psnr[\"bic\"]) / N:.4f}') \n",
    "print(f'avg PSNR superres: {sum(psnr[\"sres\"]) / N:.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4x sresnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state = torch.load('4x-sresnet.pt')\n",
    "tloss, vloss = model_state['tloss'], model_state['vloss']\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.subplots(1, 1)\n",
    "\n",
    "ax.plot(tloss, 'b-', label='train loss')\n",
    "ax.plot(vloss, 'r-', label='valid loss')\n",
    "\n",
    "ax.set_title('4x sresnet')\n",
    "ax.set_xticks(np.arange(0, len(tloss) + 1, 5))\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Best train loss: {min(tloss):.4f}')\n",
    "print(f'Best valid loss: {min(vloss):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "N = 100\n",
    "CROP = 512\n",
    "SCALE = 4\n",
    "\n",
    "ssim, psnr = evaluate(N, model_state['model'], SCALE, CROP)\n",
    "\n",
    "print(f'avg SSIM bicubic: {sum(ssim[\"bic\"]) / N:.4f}') \n",
    "print(f'avg SSIM superres:  {sum(ssim[\"sres\"]) / N:.4f}') \n",
    "\n",
    "print()\n",
    "\n",
    "print(f'avg PSNR bicubic:  {sum(psnr[\"bic\"]) / N:.4f}') \n",
    "print(f'avg PSNR superres: {sum(psnr[\"sres\"]) / N:.4f}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
