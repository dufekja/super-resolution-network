{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b6795e-af36-4327-a597-4a139e66e9c8",
   "metadata": {},
   "source": [
    "Datasets: [here](https://paperswithcode.com/datasets?q=&v=lst&o=match&mod=images&task=image-super-resolution)\n",
    "\n",
    "## Sources\n",
    "- https://paperswithcode.com/dataset/div2k\n",
    "- https://github.com/sgrvinod/Deep-Tutorials-for-PyTorch\n",
    "- https://jonathan-hui.medium.com/gan-super-resolution-gan-srgan-b471da7270ec\n",
    "- https://github.com/labmlai/annotated_deep_learning_paper_implementations\n",
    "- https://gitlab.fit.cvut.cz/dufekja4/bi-ml2-2023-dufekja4/-/blob/hw02/02/homework_02_B222.ipynb?ref_type=heads\n",
    "\n",
    "## Concepts\n",
    "- GAN - one NN for superres and second one for img rating in zero-sum game\n",
    "- deep learning residual connections\n",
    "- sub pixel convolution\n",
    "- pretrain SRmodel and then use GAN with pretrained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e4c39-41e5-4ed8-acfc-629c5030cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from torch import nn\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(SEED) \n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7f76d-c006-41e4-b5c8-bc2382630725",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgTransform(object):\n",
    "    def __init__(self, crop, scale, is_train=True, output='Tensor'):\n",
    "        self.crop = crop\n",
    "        self.scale = scale\n",
    "        self.is_train = is_train\n",
    "        self.output = output\n",
    "\n",
    "    def __call__(self, img):\n",
    "\n",
    "        if self.is_train:\n",
    "            \n",
    "            # crop HR image \n",
    "            left, top = random.randint(0, img.width - self.crop), random.randint(0, img.height - self.crop)\n",
    "            right, bottom = left + self.crop, top + self.crop\n",
    "    \n",
    "            hr_img = img.crop((left, top, right, bottom))\n",
    "        else:\n",
    "            right, bottom = (img.width // self.scale) * self.scale, (img.height // self.scale) * self.scale\n",
    "            hr_img = img.crop((0, 0, right, bottom))     \n",
    "            \n",
    "        # downscale hr image\n",
    "        lr_img = hr_img.resize((hr_img.width // self.scale, hr_img.height // self.scale), Image.BICUBIC)\n",
    "        \n",
    "        assert lr_img.width * self.scale == hr_img.width\n",
    "        assert lr_img.height * self.scale == hr_img.height\n",
    "        assert (hr_img.width % self.scale, hr_img.height % self.scale) == (0, 0)\n",
    "        \n",
    "        # convert to tensor\n",
    "        if self.output == 'Tensor':\n",
    "            return pil_to_tensor(lr_img).type(torch.float), pil_to_tensor(hr_img).type(torch.float)\n",
    "        \n",
    "        return lr_img, hr_img\n",
    "\n",
    "class Div2kDataset(Dataset):\n",
    "    def __init__(self, dir='./data', transform=None):\n",
    "        self.dir = dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.images = sorted([x for x in os.listdir(self.dir)])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(f'{self.dir}/{self.images[idx]}')\n",
    "\n",
    "        if self.transform:\n",
    "            return self.transform(img)\n",
    "            \n",
    "train_dataset = Div2kDataset('DIV2K/HR', transform=ImgTransform(crop=128, scale=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e286d9b-f806-445f-96ac-9f1941f50267",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcda663-e97a-4b62-9fca-9d040ae84856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubPixelBlock(nn.Module):\n",
    "    def __init__(self, scale=4, k=3, n_channels=64):\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "        self.k = k\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(self.n_channels, self.n_channels * (self.scale ** 2), self.k, padding=self.k // 2),\n",
    "            nn.PixelShuffle(self.scale),\n",
    "            nn.PReLU()\n",
    "        )    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class ConvBlock(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels, k=3, norm=False, activation=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "        self.norm = norm\n",
    "\n",
    "        # insert conv layer\n",
    "        self.layers = [nn.Conv2d(self.in_channels, self.out_channels, self.k, padding=self.k // 2)]\n",
    "\n",
    "        # insert batch norm layer\n",
    "        if norm: self.layers.append(nn.BatchNorm2d())\n",
    "\n",
    "        # insert activation func\n",
    "        if activation is not None:\n",
    "            self.layers.append(\n",
    "                {\n",
    "                    'prelu' : nn.PReLU(),\n",
    "                    'tanh' : nn.Tanh()\n",
    "                }[activation.lower()]\n",
    "            )\n",
    "        \n",
    "        self.conv = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "        \n",
    "\n",
    "class ResidualConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k=3, norm=False, activation=None):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "        self.norm = norm\n",
    "        self.activation = activation\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            ConvBlock(self.in_channels, self.out_channels, self.k, self.norm, self.activation),\n",
    "            ConvBlock(self.in_channels, self.out_channels, self.k, self.norm)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual, x = x, self.conv_blocks(x)\n",
    "        return x + residual\n",
    "\n",
    "class SResNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, scale=4, residual_cnt=1, sub_pix_cnt=1, norm=False):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.scale = scale\n",
    "        self.residual_cnt = residual_cnt\n",
    "        self.sub_pix_cnt = sub_pix_cnt\n",
    "        self.norm = norm\n",
    "\n",
    "        self.conv1 = ConvBlock(self.in_channels, 64, 9, activation='prelu')\n",
    "\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualConvBlock(64, 64, 3, activation='prelu') for _ in range(self.residual_cnt)]\n",
    "        )\n",
    "\n",
    "        self.conv2 = ConvBlock(64, 64, 9)\n",
    "\n",
    "        self.sub_pixel_blocks = nn.Sequential(\n",
    "            *[SubPixelBlock(self.scale) for _ in range(self.sub_pix_cnt)]\n",
    "        )\n",
    "\n",
    "        self.conv3 = ConvBlock(64, self.out_channels, 9, activation='tanh')\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # first conv with prelu\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # residual blocks with skipped conn\n",
    "        skip, x = x, self.residual_blocks(x)\n",
    "        x = self.conv2(x)\n",
    "        x += skip\n",
    "\n",
    "        # subpix blocks\n",
    "        x = self.sub_pixel_blocks(x)\n",
    "        \n",
    "        # tanh conv block\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90641e63-eebf-4ee7-affc-0ccbb1a850e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = SResNet()\n",
    "\n",
    "it = iter(train_dataloader)\n",
    "lr, hr = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a624a5f-59f9-4d14-bb99-7d8e64eb124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.shape, gen(lr).shape, hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58276c30-3cb9-489b-8b45-e35aa11a262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "def train_epoch(loader, model, optimizer):\n",
    "\n",
    "    train_loss = .0\n",
    "    \n",
    "    for batch in loader:\n",
    "        lr, hr = batch\n",
    "        lr, hr = lr.to(DEVICE), hr.to(DEVICE)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sr = model(lr)\n",
    "        \n",
    "        criterion = nn.MSELoss().to(DEVICE)\n",
    "        loss = criterion(sr, hr)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * lr.shape[0]\n",
    "        \n",
    "        del lr, hr, sr\n",
    "\n",
    "        break\n",
    "\n",
    "    print(f\"loss: {train_loss / len(loader)}\")\n",
    "\n",
    "opt = Adam(gen.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f55644-c374-4335-8766-9e30cf79f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch(train_dataloader, gen, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
